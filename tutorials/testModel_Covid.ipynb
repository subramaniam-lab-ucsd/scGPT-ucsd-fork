{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s5srinivasan/scGPT-ucsd-fork/tutorials/../scgpt/model/model.py:21: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n",
      "/home/s5srinivasan/scGPT-ucsd-fork/tutorials/../scgpt/model/multiomic_model.py:19: UserWarning: flash_attn is not installed\n",
      "  warnings.warn(\"flash_attn is not installed\")\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "import pandas as pd\n",
    "# from . import asyn\n",
    "import pickle\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "# import scvi\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import wandb\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerModel, AdversarialDiscriminator\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt import SubsetsBatchSampler\n",
    "from scgpt.utils import set_seed, category_str2int, eval_scib_metrics\n",
    "\n",
    "sc.set_figure_params(figsize=(6, 6))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msDataPath = Path(\"../data/ms\")\n",
    "covidDataPath = Path(\"../data/covid\")\n",
    "\n",
    "msDataTest = sc.read(msDataPath / \"filtered_ms_adata.h5ad\") # loading MS test data\n",
    "msData = sc.read(msDataPath / \"c_data.h5ad\") # loading MS data\n",
    "covidData = sc.read(covidDataPath / \"covidObj.h5ad\") # loading Covid data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID dataset \n",
      " Cells: 375438 \n",
      " Genes: 14063\n",
      "\n",
      "MS dataset \n",
      " Cells: 7844 \n",
      " Genes: 3000\n",
      "\n",
      "MS Test dataset \n",
      " Cells: 13468 \n",
      " Genes: 3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'COVID dataset \\n Cells: {covidData.X.shape[0]} \\n Genes: {covidData.X.shape[1]}\\n')\n",
    "print(f'MS dataset \\n Cells: {msData.X.shape[0]} \\n Genes: {msData.X.shape[1]}\\n')\n",
    "print(f'MS Test dataset \\n Cells: {msDataTest.X.shape[0]} \\n Genes: {msDataTest.X.shape[1]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common genes between MS dataset and COVID dataset: ['CFH', 'BAD', 'LAP3', 'WNT16', 'KLHL13', ..., 'DACH1', 'MARCKS', 'NEFL', 'IGHG1', 'TRAC']\n",
      "Length: 1953\n",
      "Categories (3000, object): ['A2M', 'AAMDC', 'ABCA8', 'ABCB1', ..., 'ZNF804A', 'ZNF880', 'ZWINT', 'yR211F11.2']\n",
      "Unique genes between MS dataset and COVID dataset: ['CFH' 'BAD' 'LAP3' ... 'ZZEF1' 'GNG10' 'SMIM2-AS1']\n"
     ]
    }
   ],
   "source": [
    "msGenes = msData.var['gene_name'] # 3000 unique genes, same for the others\n",
    "covidGenes = covidData.var['features'] # 14063 unique genes\n",
    "\n",
    "commonGenes = msGenes[msGenes.isin(covidGenes)].unique() # check all common genes\n",
    "uniqueGenes = pd.concat([msGenes, covidGenes]).unique() # check all unique genes - a union\n",
    "\n",
    "print(f'Common genes between MS dataset and COVID dataset: {commonGenes}')\n",
    "print(f'Unique genes between MS dataset and COVID dataset: {uniqueGenes}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
